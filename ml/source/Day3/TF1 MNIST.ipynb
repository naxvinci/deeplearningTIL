{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-c973a4adad02>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\student\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력노드, 은닉노드, 출력노드, 학습율, 반복횟수, 배치 개수 등 설정\n",
    "learning_rate = 0.1  # 학습율\n",
    "epochs = 100            # 반복횟수\n",
    "batch_size = 100      # 한번에 입력으로 주어지는 MNIST 개수\n",
    "\n",
    "input_nodes = 784     # 입력노드 개수\n",
    "hidden_nodes = 256    # 은닉노드 개수\n",
    "hidden_nodes2 = 256\n",
    "output_nodes = 10     # 출력노드 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 출력을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, input_nodes])  \n",
    "T = tf.placeholder(tf.float32, [None, output_nodes])  \n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))  # 은닉층 가중치 노드\n",
    "b2 = tf.Variable(tf.random_normal([hidden_nodes]))               # 은닉층 바이어스 노드\n",
    "\n",
    "W4 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes2]))  # 은닉층 가중치 노드\n",
    "b4 = tf.Variable(tf.random_normal([hidden_nodes2]))               # 은닉층 바이어스 노드\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_nodes2, output_nodes])) # 출력층 가중치 노드\n",
    "b3 = tf.Variable(tf.random_normal([output_nodes]))               # 출력층 바이어스 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = tf.matmul(X, W2) + b2    # 선형회귀 선형회귀 값 Z2\n",
    "A2 = tf.nn.relu(Z2)           # 은닉층 출력 값 A2, sigmoid 대신 relu 사용\n",
    "\n",
    "# 출력층 선형회귀  값 Z3, 즉 softmax 에 들어가는 입력 값\n",
    "Z3 = logits = tf.matmul(A2, W3) + b3   \n",
    "\n",
    "y = A3 = tf.nn.softmax(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(logits=Z3, labels=T) )\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A3, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  145.68887\n",
      "step =  100 , loss_val =  1.0588176\n",
      "step =  200 , loss_val =  0.58799565\n",
      "step =  300 , loss_val =  1.0855198\n",
      "step =  400 , loss_val =  0.38643402\n",
      "step =  500 , loss_val =  0.3424035\n",
      "step =  0 , loss_val =  0.63719815\n",
      "step =  100 , loss_val =  0.50945354\n",
      "step =  200 , loss_val =  0.49655274\n",
      "step =  300 , loss_val =  0.62776697\n",
      "step =  400 , loss_val =  0.6190593\n",
      "step =  500 , loss_val =  0.21567881\n",
      "step =  0 , loss_val =  0.53463435\n",
      "step =  100 , loss_val =  0.72993\n",
      "step =  200 , loss_val =  0.49982667\n",
      "step =  300 , loss_val =  0.6830675\n",
      "step =  400 , loss_val =  0.45420253\n",
      "step =  500 , loss_val =  0.4878976\n",
      "step =  0 , loss_val =  0.14129642\n",
      "step =  100 , loss_val =  0.300378\n",
      "step =  200 , loss_val =  0.5751868\n",
      "step =  300 , loss_val =  0.19211614\n",
      "step =  400 , loss_val =  0.30439442\n",
      "step =  500 , loss_val =  0.46964547\n",
      "step =  0 , loss_val =  0.59049773\n",
      "step =  100 , loss_val =  0.34673938\n",
      "step =  200 , loss_val =  0.33822292\n",
      "step =  300 , loss_val =  0.5722301\n",
      "step =  400 , loss_val =  0.6622031\n",
      "step =  500 , loss_val =  0.59779644\n",
      "step =  0 , loss_val =  0.3871416\n",
      "step =  100 , loss_val =  0.5706561\n",
      "step =  200 , loss_val =  0.34182167\n",
      "step =  300 , loss_val =  0.4877092\n",
      "step =  400 , loss_val =  0.50029176\n",
      "step =  500 , loss_val =  0.4680139\n",
      "step =  0 , loss_val =  0.8780817\n",
      "step =  100 , loss_val =  0.58350205\n",
      "step =  200 , loss_val =  0.52585596\n",
      "step =  300 , loss_val =  0.51578164\n",
      "step =  400 , loss_val =  0.69605803\n",
      "step =  500 , loss_val =  1.0773225\n",
      "step =  0 , loss_val =  0.71538144\n",
      "step =  100 , loss_val =  0.8141798\n",
      "step =  200 , loss_val =  0.54121226\n",
      "step =  300 , loss_val =  0.71968925\n",
      "step =  400 , loss_val =  0.42354342\n",
      "step =  500 , loss_val =  0.383432\n",
      "step =  0 , loss_val =  0.53091747\n",
      "step =  100 , loss_val =  0.51396203\n",
      "step =  200 , loss_val =  0.61271006\n",
      "step =  300 , loss_val =  0.3825181\n",
      "step =  400 , loss_val =  0.5656307\n",
      "step =  500 , loss_val =  0.43389502\n",
      "step =  0 , loss_val =  1.1347297\n",
      "step =  100 , loss_val =  0.44359127\n",
      "step =  200 , loss_val =  0.7506231\n",
      "step =  300 , loss_val =  0.7922917\n",
      "step =  400 , loss_val =  0.4976706\n",
      "step =  500 , loss_val =  0.5679897\n",
      "step =  0 , loss_val =  0.40520817\n",
      "step =  100 , loss_val =  0.6037825\n",
      "step =  200 , loss_val =  0.40635085\n",
      "step =  300 , loss_val =  0.63925457\n",
      "step =  400 , loss_val =  0.6253383\n",
      "step =  500 , loss_val =  0.56505483\n",
      "step =  0 , loss_val =  0.6634916\n",
      "step =  100 , loss_val =  0.7268461\n",
      "step =  200 , loss_val =  0.34168229\n",
      "step =  300 , loss_val =  0.33096558\n",
      "step =  400 , loss_val =  0.39353856\n",
      "step =  500 , loss_val =  0.38717484\n",
      "step =  0 , loss_val =  1.8774538\n",
      "step =  100 , loss_val =  0.7782543\n",
      "step =  200 , loss_val =  0.67100555\n",
      "step =  300 , loss_val =  0.59217596\n",
      "step =  400 , loss_val =  0.36675233\n",
      "step =  500 , loss_val =  0.48474786\n",
      "step =  0 , loss_val =  0.4632709\n",
      "step =  100 , loss_val =  0.7169821\n",
      "step =  200 , loss_val =  0.6045618\n",
      "step =  300 , loss_val =  0.92572296\n",
      "step =  400 , loss_val =  0.5243669\n",
      "step =  500 , loss_val =  0.9487019\n",
      "step =  0 , loss_val =  0.5419592\n",
      "step =  100 , loss_val =  0.6191335\n",
      "step =  200 , loss_val =  0.6243542\n",
      "step =  300 , loss_val =  0.5542215\n",
      "step =  400 , loss_val =  0.51721394\n",
      "step =  500 , loss_val =  1.2950771\n",
      "step =  0 , loss_val =  0.51665765\n",
      "step =  100 , loss_val =  0.71824473\n",
      "step =  200 , loss_val =  0.45667216\n",
      "step =  300 , loss_val =  0.3843311\n",
      "step =  400 , loss_val =  0.7971966\n",
      "step =  500 , loss_val =  0.5998262\n",
      "step =  0 , loss_val =  0.43418938\n",
      "step =  100 , loss_val =  0.47492188\n",
      "step =  200 , loss_val =  0.4766171\n",
      "step =  300 , loss_val =  0.7752574\n",
      "step =  400 , loss_val =  0.57511884\n",
      "step =  500 , loss_val =  0.6420198\n",
      "step =  0 , loss_val =  0.6009688\n",
      "step =  100 , loss_val =  0.53458655\n",
      "step =  200 , loss_val =  0.57505655\n",
      "step =  300 , loss_val =  0.32115892\n",
      "step =  400 , loss_val =  0.6018168\n",
      "step =  500 , loss_val =  0.6373595\n",
      "step =  0 , loss_val =  0.49814862\n",
      "step =  100 , loss_val =  0.48908857\n",
      "step =  200 , loss_val =  0.8368\n",
      "step =  300 , loss_val =  0.57152236\n",
      "step =  400 , loss_val =  0.6915025\n",
      "step =  500 , loss_val =  0.87534285\n",
      "step =  0 , loss_val =  0.47620308\n",
      "step =  100 , loss_val =  0.3521186\n",
      "step =  200 , loss_val =  1.2947404\n",
      "step =  300 , loss_val =  1.1031197\n",
      "step =  400 , loss_val =  0.7262734\n",
      "step =  500 , loss_val =  0.36250696\n",
      "step =  0 , loss_val =  0.59297085\n",
      "step =  100 , loss_val =  0.6298135\n",
      "step =  200 , loss_val =  0.84314275\n",
      "step =  300 , loss_val =  0.5640302\n",
      "step =  400 , loss_val =  0.4813794\n",
      "step =  500 , loss_val =  0.5175211\n",
      "step =  0 , loss_val =  0.6282259\n",
      "step =  100 , loss_val =  0.6102133\n",
      "step =  200 , loss_val =  0.34560096\n",
      "step =  300 , loss_val =  0.5224016\n",
      "step =  400 , loss_val =  0.6465489\n",
      "step =  500 , loss_val =  0.72187936\n",
      "step =  0 , loss_val =  0.5105646\n",
      "step =  100 , loss_val =  0.67423135\n",
      "step =  200 , loss_val =  1.1994628\n",
      "step =  300 , loss_val =  0.6339894\n",
      "step =  400 , loss_val =  0.6212286\n",
      "step =  500 , loss_val =  1.4159507\n",
      "step =  0 , loss_val =  1.1977803\n",
      "step =  100 , loss_val =  0.6458377\n",
      "step =  200 , loss_val =  0.66704196\n",
      "step =  300 , loss_val =  0.5328165\n",
      "step =  400 , loss_val =  0.6263454\n",
      "step =  500 , loss_val =  0.7173344\n",
      "step =  0 , loss_val =  0.4893782\n",
      "step =  100 , loss_val =  0.32032853\n",
      "step =  200 , loss_val =  0.5433511\n",
      "step =  300 , loss_val =  0.58412343\n",
      "step =  400 , loss_val =  0.7037411\n",
      "step =  500 , loss_val =  0.7213074\n",
      "step =  0 , loss_val =  0.57241917\n",
      "step =  100 , loss_val =  0.53952956\n",
      "step =  200 , loss_val =  1.2769878\n",
      "step =  300 , loss_val =  0.7231341\n",
      "step =  400 , loss_val =  0.5830078\n",
      "step =  500 , loss_val =  0.47421414\n",
      "step =  0 , loss_val =  0.64520174\n",
      "step =  100 , loss_val =  0.6049043\n",
      "step =  200 , loss_val =  0.71677285\n",
      "step =  300 , loss_val =  0.5351312\n",
      "step =  400 , loss_val =  0.60613173\n",
      "step =  500 , loss_val =  0.5732094\n",
      "step =  0 , loss_val =  0.6390959\n",
      "step =  100 , loss_val =  0.8005196\n",
      "step =  200 , loss_val =  4.6346188\n",
      "step =  300 , loss_val =  0.7728835\n",
      "step =  400 , loss_val =  0.5172138\n",
      "step =  500 , loss_val =  0.47258392\n",
      "step =  0 , loss_val =  0.50612104\n",
      "step =  100 , loss_val =  0.6049092\n",
      "step =  200 , loss_val =  0.57980597\n",
      "step =  300 , loss_val =  0.8403163\n",
      "step =  400 , loss_val =  0.58286405\n",
      "step =  500 , loss_val =  0.7657074\n",
      "step =  0 , loss_val =  0.7297018\n",
      "step =  100 , loss_val =  0.6117017\n",
      "step =  200 , loss_val =  0.41100723\n",
      "step =  300 , loss_val =  0.6176835\n",
      "step =  400 , loss_val =  0.61148685\n",
      "step =  500 , loss_val =  0.539724\n",
      "step =  0 , loss_val =  0.747027\n",
      "step =  100 , loss_val =  0.45031548\n",
      "step =  200 , loss_val =  0.66101557\n",
      "step =  300 , loss_val =  0.6040042\n",
      "step =  400 , loss_val =  0.66426486\n",
      "step =  500 , loss_val =  0.44429532\n",
      "step =  0 , loss_val =  0.5563561\n",
      "step =  100 , loss_val =  0.42835212\n",
      "step =  200 , loss_val =  0.52271986\n",
      "step =  300 , loss_val =  0.69189334\n",
      "step =  400 , loss_val =  0.5996688\n",
      "step =  500 , loss_val =  0.5347147\n",
      "step =  0 , loss_val =  0.39581454\n",
      "step =  100 , loss_val =  0.5598793\n",
      "step =  200 , loss_val =  0.5004632\n",
      "step =  300 , loss_val =  6.095272\n",
      "step =  400 , loss_val =  0.6756663\n",
      "step =  500 , loss_val =  0.6766401\n",
      "step =  0 , loss_val =  0.73208696\n",
      "step =  100 , loss_val =  0.48936412\n",
      "step =  200 , loss_val =  0.50701326\n",
      "step =  300 , loss_val =  0.6617221\n",
      "step =  400 , loss_val =  0.58131975\n",
      "step =  500 , loss_val =  0.62165457\n",
      "step =  0 , loss_val =  0.58266795\n",
      "step =  100 , loss_val =  0.5363213\n",
      "step =  200 , loss_val =  0.73282427\n",
      "step =  300 , loss_val =  0.89356005\n",
      "step =  400 , loss_val =  0.71399033\n",
      "step =  500 , loss_val =  0.67405516\n",
      "step =  0 , loss_val =  0.683202\n",
      "step =  100 , loss_val =  0.6959154\n",
      "step =  200 , loss_val =  0.8172363\n",
      "step =  300 , loss_val =  0.6135607\n",
      "step =  400 , loss_val =  0.8099408\n",
      "step =  500 , loss_val =  0.5481401\n",
      "step =  0 , loss_val =  0.48835588\n",
      "step =  100 , loss_val =  0.98382217\n",
      "step =  200 , loss_val =  0.60875237\n",
      "step =  300 , loss_val =  1.0058093\n",
      "step =  400 , loss_val =  0.50109226\n",
      "step =  500 , loss_val =  0.6834943\n",
      "step =  0 , loss_val =  0.6458557\n",
      "step =  100 , loss_val =  0.40375882\n",
      "step =  200 , loss_val =  0.81996363\n",
      "step =  300 , loss_val =  0.7364196\n",
      "step =  400 , loss_val =  0.4038414\n",
      "step =  500 , loss_val =  0.64973885\n",
      "step =  0 , loss_val =  1.1215607\n",
      "step =  100 , loss_val =  0.6255187\n",
      "step =  200 , loss_val =  0.55299383\n",
      "step =  300 , loss_val =  0.6547937\n",
      "step =  400 , loss_val =  0.5318681\n",
      "step =  500 , loss_val =  0.7008598\n",
      "step =  0 , loss_val =  0.6175296\n",
      "step =  100 , loss_val =  0.7484024\n",
      "step =  200 , loss_val =  0.89540094\n",
      "step =  300 , loss_val =  0.6258003\n",
      "step =  400 , loss_val =  1.9411898\n",
      "step =  500 , loss_val =  0.52956396\n",
      "step =  0 , loss_val =  0.48074275\n",
      "step =  100 , loss_val =  0.46355549\n",
      "step =  200 , loss_val =  0.48600683\n",
      "step =  300 , loss_val =  1.0108322\n",
      "step =  400 , loss_val =  0.6441105\n",
      "step =  500 , loss_val =  2.2001863\n",
      "step =  0 , loss_val =  0.6449217\n",
      "step =  100 , loss_val =  1.0283014\n",
      "step =  200 , loss_val =  0.50288427\n",
      "step =  300 , loss_val =  0.71436775\n",
      "step =  400 , loss_val =  0.5129479\n",
      "step =  500 , loss_val =  0.57135254\n",
      "step =  0 , loss_val =  0.61619246\n",
      "step =  100 , loss_val =  0.57624865\n",
      "step =  200 , loss_val =  0.8484898\n",
      "step =  300 , loss_val =  0.5271204\n",
      "step =  400 , loss_val =  1.2750733\n",
      "step =  500 , loss_val =  1.8656207\n",
      "step =  0 , loss_val =  0.57423997\n",
      "step =  100 , loss_val =  0.71155286\n",
      "step =  200 , loss_val =  0.4547075\n",
      "step =  300 , loss_val =  0.8212571\n",
      "step =  400 , loss_val =  0.4009071\n",
      "step =  500 , loss_val =  0.86924666\n",
      "step =  0 , loss_val =  0.6596682\n",
      "step =  100 , loss_val =  0.6031156\n",
      "step =  200 , loss_val =  0.64931655\n",
      "step =  300 , loss_val =  0.68036085\n",
      "step =  400 , loss_val =  0.94003046\n",
      "step =  500 , loss_val =  0.8564638\n",
      "step =  0 , loss_val =  0.7941713\n",
      "step =  100 , loss_val =  0.76528656\n",
      "step =  200 , loss_val =  0.5298582\n",
      "step =  300 , loss_val =  0.7282879\n",
      "step =  400 , loss_val =  0.59286463\n",
      "step =  500 , loss_val =  0.8052346\n",
      "step =  0 , loss_val =  0.46505576\n",
      "step =  100 , loss_val =  0.76933366\n",
      "step =  200 , loss_val =  0.6653635\n",
      "step =  300 , loss_val =  0.6912122\n",
      "step =  400 , loss_val =  0.7289555\n",
      "step =  500 , loss_val =  0.8123564\n",
      "step =  0 , loss_val =  0.74913657\n",
      "step =  100 , loss_val =  0.7061594\n",
      "step =  200 , loss_val =  0.71104544\n",
      "step =  300 , loss_val =  0.69803506\n",
      "step =  400 , loss_val =  0.64506525\n",
      "step =  500 , loss_val =  0.792009\n",
      "step =  0 , loss_val =  0.6243857\n",
      "step =  100 , loss_val =  3.0260477\n",
      "step =  200 , loss_val =  0.96549225\n",
      "step =  300 , loss_val =  0.809696\n",
      "step =  400 , loss_val =  0.582023\n",
      "step =  500 , loss_val =  0.78699094\n",
      "step =  0 , loss_val =  0.72502935\n",
      "step =  100 , loss_val =  0.75846696\n",
      "step =  200 , loss_val =  0.68889266\n",
      "step =  300 , loss_val =  0.6191962\n",
      "step =  400 , loss_val =  1.0939913\n",
      "step =  500 , loss_val =  0.7889319\n",
      "step =  0 , loss_val =  0.54194933\n",
      "step =  100 , loss_val =  0.7060002\n",
      "step =  200 , loss_val =  0.70208496\n",
      "step =  300 , loss_val =  0.78781587\n",
      "step =  400 , loss_val =  0.96715873\n",
      "step =  500 , loss_val =  0.70049006\n",
      "step =  0 , loss_val =  0.93607116\n",
      "step =  100 , loss_val =  1.2427772\n",
      "step =  200 , loss_val =  0.60211104\n",
      "step =  300 , loss_val =  0.7478054\n",
      "step =  400 , loss_val =  0.71808845\n",
      "step =  500 , loss_val =  0.82104087\n",
      "step =  0 , loss_val =  0.68458104\n",
      "step =  100 , loss_val =  0.75993025\n",
      "step =  200 , loss_val =  0.69113976\n",
      "step =  300 , loss_val =  0.7197505\n",
      "step =  400 , loss_val =  0.6807578\n",
      "step =  500 , loss_val =  0.90759057\n",
      "step =  0 , loss_val =  0.6527577\n",
      "step =  100 , loss_val =  0.54861873\n",
      "step =  200 , loss_val =  0.49432498\n",
      "step =  300 , loss_val =  0.8545311\n",
      "step =  400 , loss_val =  0.8237371\n",
      "step =  500 , loss_val =  0.71767646\n",
      "step =  0 , loss_val =  0.5693638\n",
      "step =  100 , loss_val =  0.5685134\n",
      "step =  200 , loss_val =  0.74202216\n",
      "step =  300 , loss_val =  0.63843393\n",
      "step =  400 , loss_val =  0.7509446\n",
      "step =  500 , loss_val =  1.655585\n",
      "step =  0 , loss_val =  0.69193023\n",
      "step =  100 , loss_val =  0.78077376\n",
      "step =  200 , loss_val =  0.9506616\n",
      "step =  300 , loss_val =  0.6933217\n",
      "step =  400 , loss_val =  0.844339\n",
      "step =  500 , loss_val =  0.64632905\n",
      "step =  0 , loss_val =  0.9129991\n",
      "step =  100 , loss_val =  0.8129733\n",
      "step =  200 , loss_val =  0.8477525\n",
      "step =  300 , loss_val =  0.729099\n",
      "step =  400 , loss_val =  0.6102093\n",
      "step =  500 , loss_val =  0.7016976\n",
      "step =  0 , loss_val =  0.5648038\n",
      "step =  100 , loss_val =  0.7369524\n",
      "step =  200 , loss_val =  0.818982\n",
      "step =  300 , loss_val =  0.7421074\n",
      "step =  400 , loss_val =  0.7144455\n",
      "step =  500 , loss_val =  0.70700514\n",
      "step =  0 , loss_val =  0.78417176\n",
      "step =  100 , loss_val =  0.90520257\n",
      "step =  200 , loss_val =  0.84933984\n",
      "step =  300 , loss_val =  0.6739208\n",
      "step =  400 , loss_val =  0.7481949\n",
      "step =  500 , loss_val =  1.0640713\n",
      "step =  0 , loss_val =  0.8071754\n",
      "step =  100 , loss_val =  0.60285646\n",
      "step =  200 , loss_val =  0.5796213\n",
      "step =  300 , loss_val =  0.8329644\n",
      "step =  400 , loss_val =  0.6933392\n",
      "step =  500 , loss_val =  0.6377005\n",
      "step =  0 , loss_val =  3.1692822\n",
      "step =  100 , loss_val =  0.7336033\n",
      "step =  200 , loss_val =  0.63310707\n",
      "step =  300 , loss_val =  0.61651254\n",
      "step =  400 , loss_val =  0.97130364\n",
      "step =  500 , loss_val =  0.8054753\n",
      "step =  0 , loss_val =  0.6998665\n",
      "step =  100 , loss_val =  1.1203773\n",
      "step =  200 , loss_val =  0.5349889\n",
      "step =  300 , loss_val =  0.8615148\n",
      "step =  400 , loss_val =  0.693985\n",
      "step =  500 , loss_val =  0.78465575\n",
      "step =  0 , loss_val =  0.67349213\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-01442c29f541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mbatch_x_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_t_data\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    for i in range(epochs):    # 100 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val = sess.run(accuracy, feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
