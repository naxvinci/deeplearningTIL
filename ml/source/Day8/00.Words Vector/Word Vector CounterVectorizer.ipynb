{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: \n",
      "{'one': 12, 'of': 11, 'the': 15, 'most': 9, 'basic': 1, 'ways': 18, 'we': 19, 'can': 3, 'numerically': 10, 'represent': 13, 'words': 20, 'is': 7, 'through': 16, 'hot': 6, 'encoding': 5, 'method': 8, 'also': 0, 'sometimes': 14, 'called': 2, 'count': 4, 'vectorizing': 17}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# To create a Count Vectorizer, we simply need to instantiate one.\n",
    "# There are special parameters we can set here when making the vectorizer, but\n",
    "# for the most basic example, it is not needed.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# For our text, we are going to take some text from our previous blog post\n",
    "# about count vectorization\n",
    "sample_text = [\"One of the most basic ways we can numerically represent words \"\n",
    "               \"is through the one-hot encoding method (also sometimes called \"\n",
    "               \"count vectorizing).\"]\n",
    "\n",
    "# To actually create the vectorizer, we simply need to call fit on the text\n",
    "# data that we wish to fix\n",
    "vectorizer.fit(sample_text)\n",
    "\n",
    "# Now, we can inspect how our vectorizer vectorized the text\n",
    "# This will print out a list of words used, and their index in the vectors\n",
    "print('Vocabulary: ')\n",
    "print(vectorizer.vocabulary_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full vector: \n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# If we would like to actually create a vector, we can do so by passing the\n",
    "# text into the vectorizer to get back counts\n",
    "vector = vectorizer.transform(sample_text)\n",
    "\n",
    "# Our final vector:\n",
    "print('Full vector: ')\n",
    "print(vector.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot vector: \n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Or if we wanted to get the vector for one word:\n",
    "print('Hot vector: ')\n",
    "print(vectorizer.transform(['hot']).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot and one: \n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Or if we wanted to get multiple vectors at once to build matrices\n",
    "print('Hot and one: ')\n",
    "print(vectorizer.transform(['hot', 'one']).toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One swoop:\n",
      "[[1 1 1 1 2 1 3]]\n",
      "Vocabulary: \n",
      "{'today': 6, 'is': 2, 'the': 4, 'day': 0, 'that': 3, 'do': 1, 'thing': 5}\n"
     ]
    }
   ],
   "source": [
    "# We could also do the whole thing at once with the fit_transform method:\n",
    "print('One swoop:')\n",
    "new_text = ['Today is the day that I do the thing today, today']\n",
    "new_vectorizer = CountVectorizer()\n",
    "train_data_feature = new_vectorizer.fit_transform(new_text)\n",
    "print(train_data_feature.toarray())\n",
    "print('Vocabulary: ')\n",
    "print(new_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day', 'do', 'is', 'that', 'the', 'thing', 'today']\n"
     ]
    }
   ],
   "source": [
    "print (new_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6)\t3\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t2\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_data_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
