{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd       \n",
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv(\"testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "unlabeled_train = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "(25000, 2)\n",
      "(50000, 2)\n",
      "25000\n",
      "25000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(unlabeled_train.shape)\n",
    "\n",
    "print(train['review'].size)\n",
    "print(test['review'].size)\n",
    "print(unlabeled_train['review'].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with', 'all', 'this', 'stuff', 'go', 'down', 'at', 'the', 'moment', 'with']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize (데이터 쪼개기)\n",
    "from Word2VecUtil import Word2VecUtil\n",
    "Word2VecUtil.review_to_wordlist(train['review'][0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\student\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in train['review']:\n",
    "    sentences += Word2VecUtil.review_to_sentences(\n",
    "        review, remove_stopwords=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "795538"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for review in unlabeled_train['review']:\n",
    "    sentences += Word2VecUtil.review_to_sentences(\n",
    "        review, remove_stopwords=False)\n",
    "\n",
    "    \n",
    "len(sentences) # 단어의 개수가 아닌 문장의 개수를 찍을 것임. 단어가 긍정인지 부정인지 알기 위해서는 앞 뒤 맥락을 알아야 하기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with', 'all', 'this', 'stuff', 'go', 'down', 'at', 'the', 'moment', 'with']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gensim, konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s: %(levelname)s: %(message)s',\n",
    "                   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Word2Vec\n",
    "# parameter\n",
    "num_vector = 300 # 문자 벡터 차원 수\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "windows = 10 # 문자열 창 크기 (전후)\n",
    "downsampling = 1e-3 # 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 11:16:06,773: INFO: collecting all words and their counts\n",
      "2020-04-30 11:16:06,775: INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-04-30 11:16:06,817: INFO: PROGRESS: at sentence #10000, processed 225803 words, keeping 12465 word types\n",
      "2020-04-30 11:16:06,856: INFO: PROGRESS: at sentence #20000, processed 451892 words, keeping 17070 word types\n",
      "2020-04-30 11:16:06,898: INFO: PROGRESS: at sentence #30000, processed 671314 words, keeping 20370 word types\n",
      "2020-04-30 11:16:06,942: INFO: PROGRESS: at sentence #40000, processed 897814 words, keeping 23125 word types\n",
      "2020-04-30 11:16:06,979: INFO: PROGRESS: at sentence #50000, processed 1116962 words, keeping 25365 word types\n",
      "2020-04-30 11:16:07,019: INFO: PROGRESS: at sentence #60000, processed 1338403 words, keeping 27283 word types\n",
      "2020-04-30 11:16:07,060: INFO: PROGRESS: at sentence #70000, processed 1561579 words, keeping 29024 word types\n",
      "2020-04-30 11:16:07,100: INFO: PROGRESS: at sentence #80000, processed 1780886 words, keeping 30603 word types\n",
      "2020-04-30 11:16:07,142: INFO: PROGRESS: at sentence #90000, processed 2004995 words, keeping 32223 word types\n",
      "2020-04-30 11:16:07,181: INFO: PROGRESS: at sentence #100000, processed 2226966 words, keeping 33579 word types\n",
      "2020-04-30 11:16:07,222: INFO: PROGRESS: at sentence #110000, processed 2446580 words, keeping 34827 word types\n",
      "2020-04-30 11:16:07,260: INFO: PROGRESS: at sentence #120000, processed 2668775 words, keeping 36183 word types\n",
      "2020-04-30 11:16:07,300: INFO: PROGRESS: at sentence #130000, processed 2894303 words, keeping 37353 word types\n",
      "2020-04-30 11:16:07,344: INFO: PROGRESS: at sentence #140000, processed 3107005 words, keeping 38376 word types\n",
      "2020-04-30 11:16:07,385: INFO: PROGRESS: at sentence #150000, processed 3332627 words, keeping 39556 word types\n",
      "2020-04-30 11:16:07,422: INFO: PROGRESS: at sentence #160000, processed 3555315 words, keeping 40629 word types\n",
      "2020-04-30 11:16:07,465: INFO: PROGRESS: at sentence #170000, processed 3778655 words, keeping 41628 word types\n",
      "2020-04-30 11:16:07,503: INFO: PROGRESS: at sentence #180000, processed 3999236 words, keeping 42599 word types\n",
      "2020-04-30 11:16:07,543: INFO: PROGRESS: at sentence #190000, processed 4224449 words, keeping 43461 word types\n",
      "2020-04-30 11:16:07,597: INFO: PROGRESS: at sentence #200000, processed 4448603 words, keeping 44301 word types\n",
      "2020-04-30 11:16:07,638: INFO: PROGRESS: at sentence #210000, processed 4669967 words, keeping 45212 word types\n",
      "2020-04-30 11:16:07,681: INFO: PROGRESS: at sentence #220000, processed 4894968 words, keeping 46134 word types\n",
      "2020-04-30 11:16:07,736: INFO: PROGRESS: at sentence #230000, processed 5117545 words, keeping 46986 word types\n",
      "2020-04-30 11:16:07,796: INFO: PROGRESS: at sentence #240000, processed 5345050 words, keeping 47854 word types\n",
      "2020-04-30 11:16:07,835: INFO: PROGRESS: at sentence #250000, processed 5559165 words, keeping 48699 word types\n",
      "2020-04-30 11:16:07,884: INFO: PROGRESS: at sentence #260000, processed 5779146 words, keeping 49469 word types\n",
      "2020-04-30 11:16:07,921: INFO: PROGRESS: at sentence #270000, processed 6000435 words, keeping 50416 word types\n",
      "2020-04-30 11:16:07,966: INFO: PROGRESS: at sentence #280000, processed 6226314 words, keeping 51640 word types\n",
      "2020-04-30 11:16:08,008: INFO: PROGRESS: at sentence #290000, processed 6449474 words, keeping 52754 word types\n",
      "2020-04-30 11:16:08,052: INFO: PROGRESS: at sentence #300000, processed 6674077 words, keeping 53755 word types\n",
      "2020-04-30 11:16:08,093: INFO: PROGRESS: at sentence #310000, processed 6899391 words, keeping 54734 word types\n",
      "2020-04-30 11:16:08,136: INFO: PROGRESS: at sentence #320000, processed 7124278 words, keeping 55770 word types\n",
      "2020-04-30 11:16:08,177: INFO: PROGRESS: at sentence #330000, processed 7346021 words, keeping 56687 word types\n",
      "2020-04-30 11:16:08,223: INFO: PROGRESS: at sentence #340000, processed 7575533 words, keeping 57629 word types\n",
      "2020-04-30 11:16:08,264: INFO: PROGRESS: at sentence #350000, processed 7798803 words, keeping 58485 word types\n",
      "2020-04-30 11:16:08,304: INFO: PROGRESS: at sentence #360000, processed 8019466 words, keeping 59345 word types\n",
      "2020-04-30 11:16:08,347: INFO: PROGRESS: at sentence #370000, processed 8246654 words, keeping 60161 word types\n",
      "2020-04-30 11:16:08,384: INFO: PROGRESS: at sentence #380000, processed 8471801 words, keeping 61069 word types\n",
      "2020-04-30 11:16:08,426: INFO: PROGRESS: at sentence #390000, processed 8701551 words, keeping 61810 word types\n",
      "2020-04-30 11:16:08,464: INFO: PROGRESS: at sentence #400000, processed 8924500 words, keeping 62546 word types\n",
      "2020-04-30 11:16:08,506: INFO: PROGRESS: at sentence #410000, processed 9145850 words, keeping 63263 word types\n",
      "2020-04-30 11:16:08,544: INFO: PROGRESS: at sentence #420000, processed 9366930 words, keeping 64024 word types\n",
      "2020-04-30 11:16:08,586: INFO: PROGRESS: at sentence #430000, processed 9594467 words, keeping 64795 word types\n",
      "2020-04-30 11:16:08,625: INFO: PROGRESS: at sentence #440000, processed 9821218 words, keeping 65539 word types\n",
      "2020-04-30 11:16:08,675: INFO: PROGRESS: at sentence #450000, processed 10044980 words, keeping 66378 word types\n",
      "2020-04-30 11:16:08,723: INFO: PROGRESS: at sentence #460000, processed 10277740 words, keeping 67158 word types\n",
      "2020-04-30 11:16:08,768: INFO: PROGRESS: at sentence #470000, processed 10505665 words, keeping 67775 word types\n",
      "2020-04-30 11:16:08,808: INFO: PROGRESS: at sentence #480000, processed 10726049 words, keeping 68500 word types\n",
      "2020-04-30 11:16:08,850: INFO: PROGRESS: at sentence #490000, processed 10952793 words, keeping 69256 word types\n",
      "2020-04-30 11:16:08,889: INFO: PROGRESS: at sentence #500000, processed 11174449 words, keeping 69892 word types\n",
      "2020-04-30 11:16:08,933: INFO: PROGRESS: at sentence #510000, processed 11399724 words, keeping 70593 word types\n",
      "2020-04-30 11:16:08,974: INFO: PROGRESS: at sentence #520000, processed 11623075 words, keeping 71267 word types\n",
      "2020-04-30 11:16:09,018: INFO: PROGRESS: at sentence #530000, processed 11847473 words, keeping 71877 word types\n",
      "2020-04-30 11:16:09,061: INFO: PROGRESS: at sentence #540000, processed 12072088 words, keeping 72537 word types\n",
      "2020-04-30 11:16:09,104: INFO: PROGRESS: at sentence #550000, processed 12297639 words, keeping 73212 word types\n",
      "2020-04-30 11:16:09,143: INFO: PROGRESS: at sentence #560000, processed 12518929 words, keeping 73861 word types\n",
      "2020-04-30 11:16:09,186: INFO: PROGRESS: at sentence #570000, processed 12748076 words, keeping 74431 word types\n",
      "2020-04-30 11:16:09,226: INFO: PROGRESS: at sentence #580000, processed 12969572 words, keeping 75087 word types\n",
      "2020-04-30 11:16:09,266: INFO: PROGRESS: at sentence #590000, processed 13195097 words, keeping 75733 word types\n",
      "2020-04-30 11:16:09,307: INFO: PROGRESS: at sentence #600000, processed 13417295 words, keeping 76294 word types\n",
      "2020-04-30 11:16:09,345: INFO: PROGRESS: at sentence #610000, processed 13638318 words, keeping 76952 word types\n",
      "2020-04-30 11:16:09,386: INFO: PROGRESS: at sentence #620000, processed 13864643 words, keeping 77503 word types\n",
      "2020-04-30 11:16:09,429: INFO: PROGRESS: at sentence #630000, processed 14088929 words, keeping 78066 word types\n",
      "2020-04-30 11:16:09,483: INFO: PROGRESS: at sentence #640000, processed 14309712 words, keeping 78692 word types\n",
      "2020-04-30 11:16:09,527: INFO: PROGRESS: at sentence #650000, processed 14535468 words, keeping 79295 word types\n",
      "2020-04-30 11:16:09,582: INFO: PROGRESS: at sentence #660000, processed 14758258 words, keeping 79864 word types\n",
      "2020-04-30 11:16:09,627: INFO: PROGRESS: at sentence #670000, processed 14981651 words, keeping 80381 word types\n",
      "2020-04-30 11:16:09,671: INFO: PROGRESS: at sentence #680000, processed 15206483 words, keeping 80912 word types\n",
      "2020-04-30 11:16:09,714: INFO: PROGRESS: at sentence #690000, processed 15428676 words, keeping 81482 word types\n",
      "2020-04-30 11:16:09,759: INFO: PROGRESS: at sentence #700000, processed 15657382 words, keeping 82074 word types\n",
      "2020-04-30 11:16:09,807: INFO: PROGRESS: at sentence #710000, processed 15880371 words, keeping 82560 word types\n",
      "2020-04-30 11:16:09,857: INFO: PROGRESS: at sentence #720000, processed 16105658 words, keeping 83036 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 11:16:09,914: INFO: PROGRESS: at sentence #730000, processed 16332039 words, keeping 83571 word types\n",
      "2020-04-30 11:16:09,960: INFO: PROGRESS: at sentence #740000, processed 16553072 words, keeping 84127 word types\n",
      "2020-04-30 11:16:10,003: INFO: PROGRESS: at sentence #750000, processed 16771399 words, keeping 84599 word types\n",
      "2020-04-30 11:16:10,046: INFO: PROGRESS: at sentence #760000, processed 16990803 words, keeping 85068 word types\n",
      "2020-04-30 11:16:10,087: INFO: PROGRESS: at sentence #770000, processed 17217940 words, keeping 85644 word types\n",
      "2020-04-30 11:16:10,134: INFO: PROGRESS: at sentence #780000, processed 17448086 words, keeping 86160 word types\n",
      "2020-04-30 11:16:10,179: INFO: PROGRESS: at sentence #790000, processed 17675162 words, keeping 86665 word types\n",
      "2020-04-30 11:16:10,205: INFO: collected 86996 word types from a corpus of 17798263 raw words and 795538 sentences\n",
      "2020-04-30 11:16:10,205: INFO: Loading a fresh vocabulary\n",
      "2020-04-30 11:16:10,262: INFO: effective_min_count=40 retains 11986 unique words (13% of original 86996, drops 75010)\n",
      "2020-04-30 11:16:10,263: INFO: effective_min_count=40 leaves 17434026 word corpus (97% of original 17798263, drops 364237)\n",
      "2020-04-30 11:16:10,303: INFO: deleting the raw counts dictionary of 86996 items\n",
      "2020-04-30 11:16:10,306: INFO: sample=0.001 downsamples 50 most-common words\n",
      "2020-04-30 11:16:10,307: INFO: downsampling leaves estimated 12872359 word corpus (73.8% of prior 17434026)\n",
      "2020-04-30 11:16:10,346: INFO: estimated required memory for 11986 words and 300 dimensions: 34759400 bytes\n",
      "2020-04-30 11:16:10,347: INFO: resetting layer weights\n",
      "2020-04-30 11:16:12,635: INFO: training model with 4 workers on 11986 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2020-04-30 11:16:13,662: INFO: EPOCH 1 - PROGRESS: at 8.39% examples, 1059568 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:14,672: INFO: EPOCH 1 - PROGRESS: at 17.18% examples, 1084093 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:15,674: INFO: EPOCH 1 - PROGRESS: at 25.57% examples, 1080817 words/s, in_qsize 8, out_qsize 1\n",
      "2020-04-30 11:16:16,676: INFO: EPOCH 1 - PROGRESS: at 34.60% examples, 1098468 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:17,686: INFO: EPOCH 1 - PROGRESS: at 42.86% examples, 1090410 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:18,687: INFO: EPOCH 1 - PROGRESS: at 51.31% examples, 1090177 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:19,688: INFO: EPOCH 1 - PROGRESS: at 59.67% examples, 1090057 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:20,694: INFO: EPOCH 1 - PROGRESS: at 68.32% examples, 1091834 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:21,700: INFO: EPOCH 1 - PROGRESS: at 76.27% examples, 1083869 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:22,702: INFO: EPOCH 1 - PROGRESS: at 84.51% examples, 1081355 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:23,708: INFO: EPOCH 1 - PROGRESS: at 92.21% examples, 1073074 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:24,718: INFO: EPOCH 1 - PROGRESS: at 99.54% examples, 1061635 words/s, in_qsize 8, out_qsize 0\n",
      "2020-04-30 11:16:24,753: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-30 11:16:24,764: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-30 11:16:24,769: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-30 11:16:24,773: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-30 11:16:24,774: INFO: EPOCH - 1 : training on 17798263 raw words (12872794 effective words) took 12.1s, 1061459 effective words/s\n",
      "2020-04-30 11:16:25,787: INFO: EPOCH 2 - PROGRESS: at 7.71% examples, 983229 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:26,787: INFO: EPOCH 2 - PROGRESS: at 15.40% examples, 982491 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:27,799: INFO: EPOCH 2 - PROGRESS: at 23.98% examples, 1016798 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:28,807: INFO: EPOCH 2 - PROGRESS: at 32.62% examples, 1036250 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:29,814: INFO: EPOCH 2 - PROGRESS: at 41.27% examples, 1049931 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:30,816: INFO: EPOCH 2 - PROGRESS: at 50.05% examples, 1064572 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:31,816: INFO: EPOCH 2 - PROGRESS: at 58.63% examples, 1071284 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:32,819: INFO: EPOCH 2 - PROGRESS: at 67.40% examples, 1078837 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:33,824: INFO: EPOCH 2 - PROGRESS: at 76.27% examples, 1085073 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:34,825: INFO: EPOCH 2 - PROGRESS: at 84.94% examples, 1088401 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:35,838: INFO: EPOCH 2 - PROGRESS: at 93.68% examples, 1090453 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:36,547: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-30 11:16:36,551: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-30 11:16:36,562: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-30 11:16:36,565: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-30 11:16:36,566: INFO: EPOCH - 2 : training on 17798263 raw words (12872891 effective words) took 11.8s, 1092332 effective words/s\n",
      "2020-04-30 11:16:37,583: INFO: EPOCH 3 - PROGRESS: at 8.44% examples, 1071229 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:38,590: INFO: EPOCH 3 - PROGRESS: at 17.23% examples, 1091742 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:39,590: INFO: EPOCH 3 - PROGRESS: at 25.86% examples, 1095799 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:40,596: INFO: EPOCH 3 - PROGRESS: at 34.54% examples, 1097938 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:41,597: INFO: EPOCH 3 - PROGRESS: at 42.86% examples, 1093423 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:42,606: INFO: EPOCH 3 - PROGRESS: at 50.22% examples, 1068450 words/s, in_qsize 8, out_qsize 0\n",
      "2020-04-30 11:16:43,616: INFO: EPOCH 3 - PROGRESS: at 58.57% examples, 1068904 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:44,618: INFO: EPOCH 3 - PROGRESS: at 67.23% examples, 1074907 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:45,623: INFO: EPOCH 3 - PROGRESS: at 75.42% examples, 1071992 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:46,632: INFO: EPOCH 3 - PROGRESS: at 83.73% examples, 1070636 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:47,633: INFO: EPOCH 3 - PROGRESS: at 90.71% examples, 1055385 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:48,637: INFO: EPOCH 3 - PROGRESS: at 98.61% examples, 1051926 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:48,773: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-30 11:16:48,782: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-30 11:16:48,789: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-30 11:16:48,792: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-30 11:16:48,793: INFO: EPOCH - 3 : training on 17798263 raw words (12871264 effective words) took 12.2s, 1053217 effective words/s\n",
      "2020-04-30 11:16:49,801: INFO: EPOCH 4 - PROGRESS: at 8.23% examples, 1051221 words/s, in_qsize 6, out_qsize 1\n",
      "2020-04-30 11:16:50,811: INFO: EPOCH 4 - PROGRESS: at 16.84% examples, 1069577 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:51,814: INFO: EPOCH 4 - PROGRESS: at 25.45% examples, 1080270 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:52,823: INFO: EPOCH 4 - PROGRESS: at 33.21% examples, 1054753 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:53,824: INFO: EPOCH 4 - PROGRESS: at 41.65% examples, 1061714 words/s, in_qsize 6, out_qsize 1\n",
      "2020-04-30 11:16:54,833: INFO: EPOCH 4 - PROGRESS: at 49.38% examples, 1050566 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:55,838: INFO: EPOCH 4 - PROGRESS: at 58.07% examples, 1060435 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:56,846: INFO: EPOCH 4 - PROGRESS: at 66.28% examples, 1059621 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:57,848: INFO: EPOCH 4 - PROGRESS: at 74.46% examples, 1058815 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:16:58,857: INFO: EPOCH 4 - PROGRESS: at 82.21% examples, 1051560 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 11:16:59,858: INFO: EPOCH 4 - PROGRESS: at 90.24% examples, 1050417 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:00,861: INFO: EPOCH 4 - PROGRESS: at 98.82% examples, 1054718 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:00,972: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-30 11:17:00,984: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-30 11:17:00,991: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-30 11:17:00,993: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-30 11:17:00,994: INFO: EPOCH - 4 : training on 17798263 raw words (12873075 effective words) took 12.2s, 1055617 effective words/s\n",
      "2020-04-30 11:17:02,013: INFO: EPOCH 5 - PROGRESS: at 8.22% examples, 1039829 words/s, in_qsize 8, out_qsize 1\n",
      "2020-04-30 11:17:03,016: INFO: EPOCH 5 - PROGRESS: at 16.84% examples, 1067015 words/s, in_qsize 8, out_qsize 1\n",
      "2020-04-30 11:17:04,024: INFO: EPOCH 5 - PROGRESS: at 25.75% examples, 1088624 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:05,026: INFO: EPOCH 5 - PROGRESS: at 34.49% examples, 1095433 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:06,032: INFO: EPOCH 5 - PROGRESS: at 42.97% examples, 1094917 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:07,034: INFO: EPOCH 5 - PROGRESS: at 51.59% examples, 1097207 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:08,045: INFO: EPOCH 5 - PROGRESS: at 60.25% examples, 1099643 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:09,053: INFO: EPOCH 5 - PROGRESS: at 68.93% examples, 1100936 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:10,062: INFO: EPOCH 5 - PROGRESS: at 77.83% examples, 1105257 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:11,065: INFO: EPOCH 5 - PROGRESS: at 86.59% examples, 1107036 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:12,066: INFO: EPOCH 5 - PROGRESS: at 95.17% examples, 1106626 words/s, in_qsize 7, out_qsize 0\n",
      "2020-04-30 11:17:12,596: INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-04-30 11:17:12,602: INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-04-30 11:17:12,612: INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-04-30 11:17:12,613: INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-04-30 11:17:12,614: INFO: EPOCH - 5 : training on 17798263 raw words (12875129 effective words) took 11.6s, 1108569 effective words/s\n",
      "2020-04-30 11:17:12,614: INFO: training on a 88991315 raw words (64365153 effective words) took 60.0s, 1073139 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x2ec7927f6c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences,\n",
    "                         workers=num_workers,\n",
    "                         size=num_vector,\n",
    "                         min_count=min_word_count,\n",
    "                         window=windows,\n",
    "                         sample=downsampling)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 11:19:49,320: INFO: precomputing L2-norms of word weight vectors\n",
      "2020-04-30 11:19:49,387: INFO: saving Word2Vec object under 300vector_40min_10text, separately None\n",
      "2020-04-30 11:19:49,388: INFO: not storing attribute vectors_norm\n",
      "2020-04-30 11:19:49,389: INFO: not storing attribute cum_table\n",
      "2020-04-30 11:19:49,728: INFO: saved 300vector_40min_10text\n"
     ]
    }
   ],
   "source": [
    "# 학습 후 메모리 정리 (unload)\n",
    "model.init_sims(replace=True)\n",
    "model_name = \"300vector_40min_10text\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 11:21:30,770: WARNING: vectors for words {'germany', 'france'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tokyo'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"france england korea germany tokyo\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.6411368250846863),\n",
       " ('lad', 0.5181577205657959),\n",
       " ('millionair', 0.509803056716919),\n",
       " ('ladi', 0.50445157289505),\n",
       " ('businessman', 0.5023889541625977),\n",
       " ('farmer', 0.4863393306732178),\n",
       " ('men', 0.47393137216567993),\n",
       " ('widow', 0.46346962451934814),\n",
       " ('priest', 0.456013023853302),\n",
       " ('monk', 0.4544811248779297)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schooler', 0.6845681667327881),\n",
       " ('colleg', 0.6768841743469238),\n",
       " ('junior', 0.6104618906974792),\n",
       " ('noon', 0.5683456659317017),\n",
       " ('gym', 0.5345139503479004),\n",
       " ('tech', 0.5244364142417908),\n",
       " ('teacher', 0.5026776194572449),\n",
       " ('classroom', 0.4786299467086792),\n",
       " ('class', 0.47842496633529663),\n",
       " ('profil', 0.47160249948501587)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"school\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movi', 0.8530106544494629),\n",
       " ('flick', 0.618851900100708),\n",
       " ('documentari', 0.5829713344573975),\n",
       " ('pictur', 0.5299159288406372),\n",
       " ('cinema', 0.5103890895843506),\n",
       " ('it', 0.4875624179840088),\n",
       " ('sequel', 0.48607826232910156),\n",
       " ('effort', 0.48443078994750977),\n",
       " ('masterpiec', 0.48239487409591675),\n",
       " ('thriller', 0.4791443943977356)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unhappi', 0.4447605609893799),\n",
       " ('satisfi', 0.425656795501709),\n",
       " ('sad', 0.4185406565666199),\n",
       " ('afraid', 0.38555604219436646),\n",
       " ('bitter', 0.3830738067626953),\n",
       " ('lucki', 0.37633615732192993),\n",
       " ('happier', 0.3735358715057373),\n",
       " ('comfort', 0.363841712474823),\n",
       " ('optimist', 0.3608245253562927),\n",
       " ('upset', 0.3595258295536041)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"happi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 결과 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec으로 벡터화 한 단어를 t-SNE 를 통해 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators = 100, n_jobs = -1, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainDataVecs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainDataVecs' is not defined"
     ]
    }
   ],
   "source": [
    "%time forest = forest.fit( trainDataVecs, train[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.16 s, sys: 1.56 s, total: 6.73 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "%time score = np.mean(cross_val_score(\\\n",
    "    forest, trainDataVecs, \\\n",
    "    train['sentiment'], cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003752"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forest.predict( testDataVecs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv('Word2Vec_AverageVectors_{0:.5f}.csv'.format(score), \n",
    "              index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    12578\n",
       "1    12422\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment = output['sentiment'].value_counts()\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a87f7c690>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "fig.set_size_inches(12,5)\n",
    "sns.countplot(train['sentiment'], ax=axes[0])\n",
    "sns.countplot(output['sentiment'], ax=axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
